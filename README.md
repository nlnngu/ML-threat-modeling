# ML Threat Modeling
This repo curates materials on threat modeling on systems that uses machine learning.

# Analysis documents
### MITRE ATLAS - Adversarial Threat Landscape for Artificial-Intelligence Systems:
https://github.com/mitre/advmlthreatmatrix/

### Microsoft: Threat Modeling AI/ML Systems and Dependencies
https://docs.microsoft.com/en-us/security/engineering/threat-modeling-aiml

# Technical documents
### Microsoft: AI security risk assessment using Counterfit
https://www.microsoft.com/security/blog/2021/05/03/ai-security-risk-assessment-using-counterfit/

### Measuring the Progress of AI Research
https://www.eff.org/ai/metrics

https://github.com/AI-metrics/AI-metrics

### Intelligence Task Ontology and Knowledge Graph (ITO): A comprehensive knowledge graph of artificial intelligence tasks and benchmarks
https://github.com/OpenBioLink/ITO

### Challenges in Deploying Machine Learning: a Survey of Case Studies
https://arxiv.org/abs/2011.09926

![Challenges in Deploying Machine Learning](/figures/challenges.jpg)

### Technology Readiness Levels for Machine Learning Systems
https://arxiv.org/abs/2101.03989

"... defines a principled process to ensure robust, reliable, and responsible systems while being streamlined for ML workflows, including key distinctions from traditional software engineering."
![Technology Readiness Levels for Machine Learning Systems](/figures/TRL.jpg)

### Quality Assurance Challenges for Machine Learning Software Applications During Software Development Life Cycle Phases
https://arxiv.org/abs/2105.01195

MLSA: Machine Learning Software Applications

SDLC: Software Development Life Cycle

"... a taxonomy of MLSA quality assurance issues by mapping the various ML adoption challenges across different phases of SDLC."
![Taxonomy of MLSA quality assurance issues](/figures/MLSA.jpg)

### Green Lighting ML: Confidentiality, Integrity, and Availability of Machine Learning Systems in Deployment
https://arxiv.org/abs/2007.04693

"... automated systems for validating privacy and security of models need to be developed ..."

# Policy documents
### OECD Framework for Classifying AI Systems
https://aipo-api.buddyweb.fr/app/uploads/2021/06/Report-for-consultation_OECD.AI_Classification.pdf

Characteristics per classification dimension and key actor(s) involved:
![Characteristics per classification dimension and key actor(s) involved](/figures/actors.jpg)

The AI system lifecycle:
![The AI system lifecycle](/figures/lifecycle.jpg)

On Page 24, there is a set of possible questions to help determine AI system transparency and explainability.

### Derisking AI by design: How to build risk management into AI development
https://www.mckinsey.com/business-functions/mckinsey-analytics/our-insights/derisking-ai-by-design-how-to-build-risk-management-into-ai-development

![Derisking AI by design: How to build risk management into AI development](/figures/mackinsey.jpg)

### Deloitte: AI and risk management - Innovating with confidence
https://www2.deloitte.com/content/dam/Deloitte/nl/Documents/innovatie/deloitte-nl-innovate-lu-ai-and-risk-management.pdf

### KPMG: AI Risk and Controls Matrix
https://assets.kpmg/content/dam/kpmg/uk/pdf/2018/09/ai-risk-and-controls-matrix.pdf

### Berkeley: Guidance for the Development of AI Risk and Impact Assessments
https://cltc.berkeley.edu/2021/08/09/guidance-for-the-development-of-ai-risk-and-impact-assessments/

https://cltc.berkeley.edu/wp-content/uploads/2021/08/AI_Risk_Impact_Assessments_BRIEF.pdf

### Artificial Intelligence Governance And Auditing (AIGA) 2020-2022
"... a first-class partner network to study and develop governance models for AI as well as the services and the business ecosystem emerging around responsible AI."

https://des.utu.fi/research-group/projects/aiga/

https://ai-governance.eu/

### Top 5 Priorities for Managing AI Risk Within Gartner’s MOST Framework
https://blogs.gartner.com/avivah-litan/2021/01/21/top-5-priorities-for-managing-ai-risk-within-gartners-most-framework/
![MOST Framework](/figures/MOSTframework.jpg)

### NIST: A Proposal for Identifying and Managing Bias in Artificial Intelligence
https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.1270-draft.pdf

### EU: Robustness and Explainability of Artificial Intelligence
https://publications.jrc.ec.europa.eu/repository/handle/JRC119336

### EU: Proposal for a Regulation laying down harmonised rules on Artificial Intelligence (Artificial Intelligence Act) and amending certain Union legislative acts
https://eur-lex.europa.eu/legal-content/EN/TXT/?qid=1623335154975&uri=CELEX%3A52021PC0206

### EU: Ethics guidelines for trustworthy AI
https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai

### Centre for European Policy Studies: Artificial Intelligence and Cybersecurity
https://www.ceps.eu/wp-content/uploads/2021/05/CEPS-TFR-Artificial-Intelligence-and-Cybersecurity.pdf

Where does Europe stand on the AI and cybersecurity interplay discussion? 

AI for cybersecurity and cybersecurity for AI

### Singapore: Model AI Governance Framework
https://www.imda.gov.sg/infocomm-media-landscape/SGDigital/tech-pillars/Artificial-Intelligence

https://www.pdpc.gov.sg/-/media/files/pdpc/pdf-files/resource-for-organisation/ai/sgmodelaigovframework2.pdf

On Page 31 of the above PDF, there is the definition of "harm" to determine the level of human oversight in an organisation’s decision-making process involving AI:

![AI Harm](/figures/AIHarm.jpg)

# Projects
### HUMAINT: aiming to understand the impact of machine intelligence on human behaviour, with a focus on cognitive and socio-emotional capabilities and decision making
https://ec.europa.eu/jrc/communities/en/community/humaint
